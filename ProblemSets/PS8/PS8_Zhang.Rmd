---
title: "PS8_Zhang"
output: pdf_document
date: "2025-03-26"
---

```{r}
# Install and load required packages
library(nloptr)
library(modelsummary)

# Set the seed
set.seed(100)

# Create the data set
N <- 100000
K <- 10
X <- matrix(rnorm(N * (K - 1)), N, K - 1)
X <- cbind(rep(1, N), X)
eps <- rnorm(N, 0, 0.5)
beta <- c(1.5, -1, -0.25, 0.75, 3.5, -2, 0.5, 1, 1.25, 2)
Y <- X %*% beta + eps

# Compute OLS estimate using closed-form solution
beta_ols_closed <- solve(t(X) %*% X) %*% t(X) %*% Y
print(beta_ols_closed)
```
```{r}
# Compute OLS estimate using gradient descent
gradient_descent <- function(X, Y, beta_init, learning_rate, max_iter) {
  beta <- beta_init
  for (i in 1:max_iter) {
    gradient <- -2 * t(X) %*% (Y - X %*% beta)
    beta <- beta - learning_rate * gradient
  }
  return(beta)
}

beta_init <- rep(0, K)
learning_rate <- 0.0000003
max_iter <- 1000
beta_ols_gradient <- gradient_descent(X, Y, beta_init, learning_rate, max_iter)
print(beta_ols_gradient)
```
```{r}
### Compute OLS estimate using L-BFGS algorithm and Nelder-Mead algorithm
objective_function <- function(beta) {
  return(sum((Y - X %*% beta)^2))
}

#L-BFGS algorithm
opts <- list("algorithm" = "NLOPT_LD_LBFGS", "xtol_rel" = 1.0e-8)
gradient_wrapper <- function(beta) {
  return(-2 * t(X) %*% (Y - X %*% beta))
}
result_lbfgs <- nloptr(x0 = beta_init, eval_f = objective_function, eval_grad_f = gradient_wrapper, opts = opts)
beta_ols_lbfgs <- result_lbfgs$solution
print("OLS estimate using L-BFGS algorithm:")
print(beta_ols_lbfgs)

# Nelder-Mead algorithm
opts$algorithm <- "NLOPT_LN_NELDERMEAD"
result_nelder_mead <- nloptr(x0 = beta_init, eval_f = objective_function, opts = opts)
beta_ols_nelder_mead <- result_nelder_mead$solution
print("OLS estimate using Nelder-Mead algorithm:")
print(beta_ols_nelder_mead)
```
```{r}
# Compute MLE estimate using L-BFGS algorithm
gradient <- function(theta) {
beta <- theta[1:(length(theta) - 1)]
sig <- theta[length(theta)]
grad <- as.vector(rep(0, length(theta)))
grad[1:(length(theta) - 1)] <- -t(X) %*% (Y - X %*% beta) / (sig^2)
grad[length(theta)] <- dim(X)[1] / sig - crossprod(Y - X %*% beta) / (sig^3)
return(grad)
}

objective_function_mle <- function(theta) {
  beta <- theta[1:(length(theta) - 1)]
  sig <- theta[length(theta)]
  return(sum((Y - X %*% beta)^2) / (2 * sig^2) + length(Y) * log(sig))
}

theta_init <- c(beta_init, 1)
result_mle <- nloptr(x0 = theta_init, eval_f = objective_function_mle, eval_grad_f = gradient, opts = opts)
beta_mle <- result_mle$solution[1:(length(theta_init) - 1)]
print(beta_mle)
```
```{r}
# Compute OLS estimate using lm()
model <- lm(Y ~ X - 1)
print(coef(model))
```
```{r}
# True beta values
beta_true <- c(1.5, -1, -0.25, 0.75, 3.5, -2, 0.5, 1, 1.25, 2)

# Difference between estimated and true beta values
beta_difference <- beta_ols_closed - beta_true
print(beta_difference)
```

